---
permalink: /blog/self-vision/
share: false
toc: true
toc_label: "Table of Contents"
toc_icon: "cog"
---

# 自我视觉中心机器人运动

## 自我视觉中心

## 强化学习

学习分为两阶段的策略

1.  通过机器人下方的低分辨率scandots作为深度图像的代替，地形高度被查询(?)作为观测时传递。这种方法的计算量小且能捕捉地形的几何形状。
2.  通过第一阶段的action作为监督通过RNN学习，推理阶段根据当前的本体感觉和深度信息预测关节角度

通过两种策略实例化该训练理论

1.  单一的仅通过本体感觉和视觉数据通过RNN直接预测关节角度
2.  先通过MLP(多层感知机)处理后再使用RNN处理得到关节角度的预测

### 第一阶段的强化学习

本体感觉包括：关节角度、关节速度、角速度、侧倾、俯仰，最后的策略动作

RNN输入还包括机器人的质心、地面摩擦力、电机强度等特权信息

1.  Monolithic与RMA两种策略都可以通过本体感觉与视觉数据作为 PPO 中的 state （RMA 更加准确）
2.  奖励：一个是能量的奖惩，另一个是附加惩罚防止再复杂地形上损坏硬件
3.  环境：6\*10的矩阵排列，难度递增

### 第二阶段的监督学习

输入包括第一阶段的输出action

## 局限性：

仅能通过仿真训练机器人，若现实环境具有与仿真环境明显不同的地形特征时，需要重新构建仿真环境并重新训练
