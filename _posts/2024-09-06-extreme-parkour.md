---
permalink: /blog/extrem-parkour/
share: false
toc: true
toc_label: "Table of Contents"
toc_icon: "cog"
---

# 四足机器人的极限跑酷

基于自我中心视觉、深度图像的神经网络学习跑酷策略

## 三个想法

1.  使用scandots作为特权信息(first class citizen)
2.  允许策略根据障碍物决定自己的部署方向
3.  **<span style="background-color: #ffd40080">统一的通用reward原则</span>**

## Method

目标：训练一个单一的神经网络，输入为原始深度信息，本体传感器信号；输出关节指令

采用两段 RL 的 teacher-student 架构

第一段RL的结果成为第二段RL的标签

第一段RL使用人类提供的适当的航路点指引方向，而在第二段RL则训练网络实现从深度信息预测航向

*   对于跑酷的reward的统一标准：

    1.  奖励取 期望速度 与 在期望方向上的实际速度 中的最小值 (使得尽可能达到预期速度
    2.  为了避免机器人倾向于在障碍物边缘，加入一项reward
    3.  一项通过操作者控制的利于生物美学的reward项
    4.  正则化项

### Phase 1

以本体感觉，扫描点，目标航向，步行标志和指令速度作为输入，利用ROA训练自适应模块估计环境属性

### Phase 2

phase 1 的学习依赖于 外感受性信息 和 航向指引方向点，而这些量在真实机器人中是 无法获得的，故在phase2 采用监督学习来获得一个可以自动估计这些量的可部署策略

使用第一阶段的副本初始化网络，以减少学生在 step 时的偏差

对于航向目标，不能直接用监督学习获得的预测的航向，会导致灾难性的漂移，而使用教师学生混合MTS方法得到的航向
